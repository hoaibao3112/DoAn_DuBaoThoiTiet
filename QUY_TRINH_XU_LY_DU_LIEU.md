# üìä QUY TR√åNH X·ª¨ L√ù D·ªÆ LI·ªÜU - D·ª∞ √ÅN CH·∫§T L∆Ø·ª¢NG KH√îNG KH√ç (AQI)

## üéØ T·ªïng quan d·ªØ li·ªáu

**Dataset:** `station_day.csv` - D·ªØ li·ªáu ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ theo ng√†y t·ª´ c√°c tr·∫°m quan tr·∫Øc

**Th√¥ng tin:**
- **108,037 records** (h∆°n 100k d√≤ng d·ªØ li·ªáu)
- **16 c·ªôt:** StationId, Date, PM2.5, PM10, NO, NO2, NOx, NH3, CO, SO2, O3, Benzene, Toluene, Xylene, AQI, AQI_Bucket
- **Th·ªùi gian:** 2017-11-24 ƒë·∫øn 2018-07-11
- **C√°c tr·∫°m:** AP001, v√† nhi·ªÅu tr·∫°m kh√°c (c·∫ßn kh√°m ph√°)

**Ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ (AQI_Bucket):**
- Good (T·ªët): 0-50
- Satisfactory (Kh√°): 51-100  
- Moderate (Trung b√¨nh): 101-200
- Poor (K√©m): 201-300
- Very Poor (R·∫•t k√©m): 301-400
- Severe (Nguy hi·ªÉm): 401+

---

## üîÑ QUY TR√åNH X·ª¨ L√ù D·ªÆ LI·ªÜU HO√ÄN CH·ªàNH

### Phase 1: THU TH·∫¨P & L√ÄM S·∫†CH D·ªÆ LI·ªÜU (ETL)

#### 1.1. Extract (Tr√≠ch xu·∫•t)
```python
# ƒê·ªçc CSV, parse dates, x·ª≠ l√Ω encoding
import pandas as pd

df = pd.read_csv('station_day.csv', parse_dates=['Date'])
```

**Nhi·ªám v·ª•:**
- ‚úÖ Load CSV v√†o pandas DataFrame
- ‚úÖ Parse Date column th√†nh datetime
- ‚úÖ Ki·ªÉm tra dtypes c·ªßa t·ª´ng c·ªôt
- ‚úÖ X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng tr·∫°m (unique StationId)
- ‚úÖ Ph√¢n t√≠ch kho·∫£ng th·ªùi gian d·ªØ li·ªáu

#### 1.2. Transform (Bi·∫øn ƒë·ªïi)

**A. X·ª≠ l√Ω Missing Values**
```python
# Ki·ªÉm tra missing
missing_summary = df.isnull().sum()

# Strategies:
# - Fillna v·ªõi median/mean cho pollutants (PM2.5, PM10, etc.)
# - Interpolate theo time series (ffill/bfill)
# - Drop rows n·∫øu AQI missing (target variable)
```

**B. Feature Engineering**
```python
# T·∫°o features m·ªõi t·ª´ Date
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['DayOfWeek'] = df['Date'].dt.dayofweek
df['Quarter'] = df['Date'].dt.quarter
df['WeekOfYear'] = df['Date'].dt.isocalendar().week

# T·∫°o rolling statistics (trung b√¨nh 7 ng√†y, 30 ng√†y)
df['PM2.5_MA7'] = df.groupby('StationId')['PM2.5'].transform(lambda x: x.rolling(7, min_periods=1).mean())
df['PM2.5_MA30'] = df.groupby('StationId')['PM2.5'].transform(lambda x: x.rolling(30, min_periods=1).mean())

# Lag features (gi√° tr·ªã ng√†y h√¥m tr∆∞·ªõc)
df['PM2.5_lag1'] = df.groupby('StationId')['PM2.5'].shift(1)
df['PM2.5_lag7'] = df.groupby('StationId')['PM2.5'].shift(7)

# T·ªâ l·ªá c√°c ch·∫•t √¥ nhi·ªÖm
df['PM_ratio'] = df['PM2.5'] / (df['PM10'] + 1)  # +1 tr√°nh chia 0
df['NOx_total'] = df['NO'] + df['NO2']

# Binary features
df['is_weekend'] = df['DayOfWeek'].isin([5, 6]).astype(int)
df['is_winter'] = df['Month'].isin([11, 12, 1, 2]).astype(int)
```

**C. Outlier Detection**
```python
from scipy import stats

# Z-score method
z_scores = np.abs(stats.zscore(df[['PM2.5', 'PM10', 'AQI']].fillna(0)))
df['is_outlier'] = (z_scores > 3).any(axis=1)

# IQR method
Q1 = df['PM2.5'].quantile(0.25)
Q3 = df['PM2.5'].quantile(0.75)
IQR = Q3 - Q1
df['PM2.5_outlier'] = ((df['PM2.5'] < (Q1 - 1.5 * IQR)) | (df['PM2.5'] > (Q3 + 1.5 * IQR)))
```

#### 1.3. Load (L∆∞u tr·ªØ)
```python
# L∆∞u cleaned data
df_clean.to_csv('data/cleaned/station_day_clean.csv', index=False)

# Ho·∫∑c l∆∞u v√†o database
# df_clean.to_sql('air_quality', con=engine, if_exists='replace')
```

---

### Phase 2: PH√ÇN T√çCH KH√ÅM PH√Å D·ªÆ LI·ªÜU (EDA)

#### 2.1. Descriptive Statistics
```python
# Th·ªëng k√™ m√¥ t·∫£
print(df.describe())

# Ph√¢n b·ªë AQI_Bucket
print(df['AQI_Bucket'].value_counts())

# Correlation matrix
import seaborn as sns
corr_matrix = df[['PM2.5', 'PM10', 'NO2', 'O3', 'AQI']].corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
```

#### 2.2. Visualization Insights

**A. Time Series Analysis**
- Xu h∆∞·ªõng PM2.5/AQI theo th·ªùi gian
- Seasonal patterns (m√πa ƒë√¥ng √¥ nhi·ªÖm cao h∆°n?)
- Weekly patterns (cu·ªëi tu·∫ßn kh√°c ng√†y th∆∞·ªùng?)

**B. Geographic Analysis**
- So s√°nh AQI gi·ªØa c√°c tr·∫°m
- Tr·∫°m n√†o √¥ nhi·ªÖm nh·∫•t/s·∫°ch nh·∫•t?
- Heatmap theo v·ªã tr√≠ (n·∫øu c√≥ lat/lon)

**C. Pollutant Relationships**
- PM2.5 vs PM10 correlation
- NO2 impact on AQI
- Benzene/Toluene levels

**D. Alert Thresholds**
- S·ªë ng√†y AQI > 200 (Poor/Very Poor)
- Frequency c·ªßa AQI_Bucket levels
- Identify pollution spikes

---

### Phase 3: M√î H√åNH D·ª∞ B√ÅO (MACHINE LEARNING)

#### 3.1. B√†i to√°n d·ª± b√°o

**Option A: Regression - D·ª± b√°o AQI s·ªë (li√™n t·ª•c)**
- Input: PM2.5, PM10, NO2, date features, lag features
- Output: AQI value (0-500)
- Models: Linear Regression, Random Forest, XGBoost, LSTM

**Option B: Classification - D·ª± b√°o AQI_Bucket (ph√¢n lo·∫°i)**
- Input: t∆∞∆°ng t·ª±
- Output: Good/Satisfactory/Moderate/Poor/Very Poor/Severe
- Models: Logistic Regression, Random Forest, XGBoost, Neural Network

**Option C: Time Series Forecasting - D·ª± b√°o ng√†y mai**
- Input: l·ªãch s·ª≠ 7-30 ng√†y tr∆∞·ªõc
- Output: PM2.5/AQI ng√†y mai
- Models: ARIMA, Prophet, LSTM/GRU

#### 3.2. Model Pipeline

```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score

# Prepare data
features = ['PM2.5', 'PM10', 'NO2', 'O3', 'Month', 'DayOfWeek', 
            'PM2.5_MA7', 'PM2.5_lag1']
X = df[features].fillna(0)
y = df['AQI'].fillna(0)

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.2f}, R¬≤: {r2:.3f}")

# Save model
import joblib
joblib.dump(model, 'models/aqi_predictor.pkl')
```

#### 3.3. Feature Importance
```python
# Xem feature n√†o quan tr·ªçng nh·∫•t
importances = model.feature_importances_
feature_importance_df = pd.DataFrame({
    'feature': features,
    'importance': importances
}).sort_values('importance', ascending=False)

print(feature_importance_df)
```

---

### Phase 4: API D·ª∞ B√ÅO (FASTAPI SERVICE)

#### 4.1. FastAPI Endpoints

**File: `app/aqi_predictor.py`**
```python
import joblib
import pandas as pd
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI(title="AQI Prediction API")

# Load model
model = joblib.load('models/aqi_predictor.pkl')

class AQIRequest(BaseModel):
    pm25: float
    pm10: float
    no2: float
    o3: float
    month: int
    day_of_week: int

class AQIResponse(BaseModel):
    predicted_aqi: float
    aqi_category: str
    health_impact: str
    recommendation: str

def get_aqi_category(aqi: float) -> str:
    if aqi <= 50: return "Good"
    elif aqi <= 100: return "Satisfactory"
    elif aqi <= 200: return "Moderate"
    elif aqi <= 300: return "Poor"
    elif aqi <= 400: return "Very Poor"
    else: return "Severe"

def get_health_impact(category: str) -> str:
    impacts = {
        "Good": "Minimal impact",
        "Satisfactory": "Minor breathing discomfort to sensitive people",
        "Moderate": "Breathing discomfort to people with lung, asthma, heart disease",
        "Poor": "Breathing discomfort to most people on prolonged exposure",
        "Very Poor": "Respiratory illness on prolonged exposure",
        "Severe": "Affects healthy people and seriously impacts those with existing diseases"
    }
    return impacts.get(category, "Unknown")

def get_recommendation(category: str) -> str:
    recs = {
        "Good": "Air quality is satisfactory. Enjoy outdoor activities!",
        "Satisfactory": "Sensitive individuals should consider limiting outdoor activities.",
        "Moderate": "People with respiratory conditions should reduce outdoor activities.",
        "Poor": "Avoid outdoor activities. Wear N95 mask if going outside.",
        "Very Poor": "Stay indoors. Use air purifiers. Avoid physical activities.",
        "Severe": "Medical emergency! Stay indoors with doors/windows closed."
    }
    return recs.get(category, "Unknown")

@app.post("/predict", response_model=AQIResponse)
def predict_aqi(request: AQIRequest):
    # Prepare input
    input_data = pd.DataFrame([{
        'PM2.5': request.pm25,
        'PM10': request.pm10,
        'NO2': request.no2,
        'O3': request.o3,
        'Month': request.month,
        'DayOfWeek': request.day_of_week,
        'PM2.5_MA7': request.pm25,  # simplified
        'PM2.5_lag1': request.pm25  # simplified
    }])
    
    # Predict
    prediction = model.predict(input_data)[0]
    category = get_aqi_category(prediction)
    
    return AQIResponse(
        predicted_aqi=round(prediction, 2),
        aqi_category=category,
        health_impact=get_health_impact(category),
        recommendation=get_recommendation(category)
    )

@app.get("/station/{station_id}/historical")
def get_historical_data(station_id: str, start_date: str, end_date: str):
    """L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ c·ªßa m·ªôt tr·∫°m"""
    df = pd.read_csv('data/cleaned/station_day_clean.csv', parse_dates=['Date'])
    filtered = df[
        (df['StationId'] == station_id) & 
        (df['Date'] >= start_date) & 
        (df['Date'] <= end_date)
    ]
    return filtered.to_dict(orient='records')

@app.get("/stations/worst")
def get_worst_stations(limit: int = 10):
    """Top tr·∫°m c√≥ AQI cao nh·∫•t"""
    df = pd.read_csv('data/cleaned/station_day_clean.csv')
    worst = df.groupby('StationId')['AQI'].mean().sort_values(ascending=False).head(limit)
    return worst.to_dict()
```

#### 4.2. Test API
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "pm25": 120.5,
    "pm10": 180.3,
    "no2": 45.2,
    "o3": 60.1,
    "month": 12,
    "day_of_week": 1
  }'
```

---

### Phase 5: C·∫¢NH B√ÅO T·ª∞ ƒê·ªòNG (n8n WORKFLOW)

#### 5.1. Use Cases

**A. Daily AQI Report**
- n8n schedule trigger (m·ªói s√°ng 7AM)
- G·ªçi API `/predict` v·ªõi d·ªØ li·ªáu m·ªõi nh·∫•t
- G·ª≠i b√°o c√°o qua:
  - Zalo message
  - Email
  - Telegram
  - SMS (Twilio)

**B. Alert When AQI > Threshold**
- n8n webhook nh·∫≠n real-time sensor data
- G·ªçi `/predict` ƒë·ªÉ d·ª± b√°o AQI
- N·∫øu AQI > 200 (Poor):
  - G·ª≠i c·∫£nh b√°o kh·∫©n c·∫•p
  - L∆∞u v√†o database
  - Notify qua nhi·ªÅu channels

**C. Weekly Trend Report**
- n8n schedule (m·ªói Ch·ªß nh·∫≠t)
- G·ªçi `/station/*/historical` ƒë·ªÉ l·∫•y data tu·∫ßn
- T·∫°o visualization (chart)
- G·ª≠i b√°o c√°o PDF qua email

**D. Data Pipeline Automation**
- n8n FTP/HTTP trigger (nh·∫≠n file CSV m·ªõi)
- Ch·∫°y ETL script (Python)
- Retrain model n·∫øu data ƒë·ªß l·ªõn
- Deploy model m·ªõi l√™n production
- Notify team qua Slack

#### 5.2. n8n Workflow Example: Daily AQI Alert

**Nodes:**
1. **Schedule Trigger** - Ch·∫°y m·ªói ng√†y 7AM
2. **HTTP Request** - L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t t·ª´ sensor API
3. **HTTP Request** - POST `/predict` v·ªõi data
4. **Function** - Parse response, format message
5. **IF** - Check if AQI > 150
   - **YES branch:**
     - **Zalo Message** - G·ª≠i c·∫£nh b√°o
     - **Email** - G·ª≠i cho danh s√°ch subscribers
     - **Google Sheets** - Log v√†o spreadsheet
   - **NO branch:**
     - **Telegram** - G·ª≠i tin nh·∫π nh√†ng
6. **Set** - Log execution status

---

### Phase 6: DASHBOARD & VISUALIZATION

#### 6.1. Streamlit Dashboard

**File: `dashboard/app.py`**
```python
import streamlit as st
import pandas as pd
import plotly.express as px
import requests

st.set_page_config(page_title="AQI Monitor", layout="wide")

st.title("üåç Air Quality Index Dashboard")

# Load data
@st.cache_data
def load_data():
    return pd.read_csv('data/cleaned/station_day_clean.csv', parse_dates=['Date'])

df = load_data()

# Sidebar filters
station = st.sidebar.selectbox("Select Station", df['StationId'].unique())
date_range = st.sidebar.date_input("Date Range", [df['Date'].min(), df['Date'].max()])

# Filter data
filtered = df[
    (df['StationId'] == station) & 
    (df['Date'] >= pd.to_datetime(date_range[0])) & 
    (df['Date'] <= pd.to_datetime(date_range[1]))
]

# Metrics
col1, col2, col3, col4 = st.columns(4)
col1.metric("Average AQI", f"{filtered['AQI'].mean():.1f}")
col2.metric("Max PM2.5", f"{filtered['PM2.5'].max():.1f}")
col3.metric("Days > 200 AQI", len(filtered[filtered['AQI'] > 200]))
col4.metric("Current Category", filtered.iloc[-1]['AQI_Bucket'] if len(filtered) > 0 else "N/A")

# Time series chart
fig = px.line(filtered, x='Date', y='AQI', title='AQI Trend')
st.plotly_chart(fig, use_container_width=True)

# Pollutant comparison
fig2 = px.box(filtered, y=['PM2.5', 'PM10', 'NO2', 'O3'], title='Pollutant Distribution')
st.plotly_chart(fig2, use_container_width=True)

# Prediction section
st.header("üîÆ AQI Prediction")
col1, col2 = st.columns(2)
pm25 = col1.number_input("PM2.5", value=100.0)
pm10 = col2.number_input("PM10", value=150.0)

if st.button("Predict AQI"):
    response = requests.post(
        "http://localhost:8000/predict",
        json={
            "pm25": pm25,
            "pm10": pm10,
            "no2": 40.0,
            "o3": 50.0,
            "month": 12,
            "day_of_week": 1
        }
    )
    result = response.json()
    st.success(f"Predicted AQI: {result['predicted_aqi']} - {result['aqi_category']}")
    st.info(result['recommendation'])
```

#### 6.2. Run Dashboard
```bash
streamlit run dashboard/app.py
```

---

## üéØ TRI·ªÇN KHAI V√Ä S·ª¨ D·ª§NG

### C·∫•u tr√∫c th∆∞ m·ª•c ƒë·ªÅ xu·∫•t

```
Doan_PTDL/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ station_day.csv
‚îÇ   ‚îî‚îÄ‚îÄ cleaned/
‚îÇ       ‚îî‚îÄ‚îÄ station_day_clean.csv
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_Feature_Engineering.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_Modeling.ipynb
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # FastAPI main (Zalo AI)
‚îÇ   ‚îú‚îÄ‚îÄ aqi_predictor.py      # AQI prediction endpoints
‚îÇ   ‚îú‚îÄ‚îÄ etl.py                # Data processing functions
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ aqi_predictor.pkl
‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îî‚îÄ‚îÄ app.py                # Streamlit dashboard
‚îú‚îÄ‚îÄ n8n-workflows/
‚îÇ   ‚îú‚îÄ‚îÄ Zalo_AI_Assistant.json
‚îÇ   ‚îî‚îÄ‚îÄ Daily_AQI_Alert.json
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train_model.py
‚îÇ   ‚îî‚îÄ‚îÄ update_data.py
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

### Workflow ho√†n ch·ªânh

```
1. D·ªØ li·ªáu m·ªõi ‚Üí CSV file
   ‚Üì
2. n8n trigger ‚Üí Run ETL script
   ‚Üì
3. ETL: Clean + Feature Engineering
   ‚Üì
4. Save to cleaned/station_day_clean.csv
   ‚Üì
5. Retrain model (n·∫øu c·∫ßn)
   ‚Üì
6. Deploy model ‚Üí FastAPI
   ‚Üì
7. n8n schedule ‚Üí Daily prediction
   ‚Üì
8. If AQI > threshold ‚Üí Alert (Zalo/Email/SMS)
   ‚Üì
9. Dashboard update real-time
```

---

## üí° ƒê·ªÄ XU·∫§T T√çNH NƒÇNG HAY V√Ä H·ªÆU √çCH

### 1. **Real-time AQI Monitor + Alert System**
**M√¥ t·∫£:** H·ªá th·ªëng gi√°m s√°t v√† c·∫£nh b√°o ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ t·ª± ƒë·ªông.

**Lu·ªìng ho·∫°t ƒë·ªông:**
- Sensor/API g·ª≠i d·ªØ li·ªáu real-time ‚Üí n8n webhook
- n8n g·ªçi FastAPI `/predict` ‚Üí D·ª± b√°o AQI
- N·∫øu AQI > ng∆∞·ª°ng c·∫£nh b√°o:
  - G·ª≠i Zalo message cho ng∆∞·ªùi d√πng ƒëƒÉng k√Ω
  - G·ª≠i email/SMS
  - Push notification (qua Firebase)
  - C·∫≠p nh·∫≠t dashboard
  - L∆∞u v√†o database ƒë·ªÉ ph√¢n t√≠ch sau

**Gi√° tr·ªã:**
- B·∫£o v·ªá s·ª©c kh·ªèe: Ng∆∞·ªùi d√πng bi·∫øt khi n√†o n√™n ·ªü trong nh√†
- Proactive: C·∫£nh b√°o tr∆∞·ªõc khi AQI tr·ªü n√™n nguy hi·ªÉm
- Multi-channel: ƒê·∫£m b·∫£o ng∆∞·ªùi d√πng nh·∫≠n ƒë∆∞·ª£c th√¥ng b√°o

### 2. **Personalized Health Recommendations**
**M√¥ t·∫£:** ƒê·ªÅ xu·∫•t c√° nh√¢n ho√° d·ª±a tr√™n AQI v√† profile s·ª©c kh·ªèe.

**Profile ng∆∞·ªùi d√πng:**
- Tu·ªïi, gi·ªõi t√≠nh
- T√¨nh tr·∫°ng s·ª©c kh·ªèe (hen suy·ªÖn, COPD, tim m·∫°ch)
- V·ªã tr√≠ (tr·∫°m n√†o g·∫ßn nh·∫•t)
- Ho·∫°t ƒë·ªông th∆∞·ªùng ng√†y (ch·∫°y b·ªô, ƒë·∫°p xe)

**Recommendations:**
- AQI < 50: "Tuy·ªát v·ªùi! B·∫°n c√≥ th·ªÉ ch·∫°y b·ªô ngo√†i tr·ªùi."
- AQI 100-150 + Asthma: "N√™n h·∫°n ch·∫ø ho·∫°t ƒë·ªông ngo√†i tr·ªùi. Mang theo thu·ªëc x·ªãt."
- AQI > 200: "Nguy hi·ªÉm! ·ªû trong nh√†, ƒë√≥ng c·ª≠a s·ªï, b·∫≠t m√°y l·ªçc kh√¥ng kh√≠."

### 3. **Comparative Station Analysis**
**M√¥ t·∫£:** So s√°nh ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ gi·ªØa c√°c khu v·ª±c.

**Features:**
- Map view: Heatmap AQI theo v·ªã tr√≠ ƒë·ªãa l√Ω
- Ranking: Top 10 tr·∫°m s·∫°ch nh·∫•t/√¥ nhi·ªÖm nh·∫•t
- Trend comparison: So s√°nh xu h∆∞·ªõng gi·ªØa 2-3 tr·∫°m
- Best time to visit: "Khu v·ª±c X s·∫°ch nh·∫•t v√†o bu·ªïi s√°ng"

**Use case:**
- Ch·ªçn n∆°i ·ªü: Ng∆∞·ªùi mua nh√† xem khu n√†o kh√¥ng kh√≠ t·ªët nh·∫•t
- L·∫≠p k·∫ø ho·∫°ch du l·ªãch: Tr√°nh khu v·ª±c √¥ nhi·ªÖm
- Quy·∫øt ƒë·ªãnh ƒëi l√†m: Ch·ªçn route √≠t √¥ nhi·ªÖm

### 4. **7-Day AQI Forecast**
**M√¥ t·∫£:** D·ª± b√°o AQI 7 ng√†y t·ªõi (nh∆∞ d·ª± b√°o th·ªùi ti·∫øt).

**Model:** Time series (LSTM, Prophet)
**Input:** L·ªãch s·ª≠ 30 ng√†y + seasonal patterns
**Output:** AQI d·ª± b√°o cho 7 ng√†y t·ªõi

**UI:**
```
Mon  Tue  Wed  Thu  Fri  Sat  Sun
120  95   88   105  130  115  90
üü°   üü¢   üü¢   üü°   üü†   üü°   üü¢
```

**Use case:**
- L·∫≠p l·ªãch ho·∫°t ƒë·ªông ngo√†i tr·ªùi (picnic, marathon)
- Quy·∫øt ƒë·ªãnh b·∫≠t m√°y l·ªçc kh√¥ng kh√≠
- Chu·∫©n b·ªã kh·∫©u trang tr∆∞·ªõc

### 5. **Pollution Source Analysis**
**M√¥ t·∫£:** Ph√¢n t√≠ch nguy√™n nh√¢n √¥ nhi·ªÖm ch√≠nh.

**Analysis:**
- Feature importance: PM2.5 t·ª´ ƒë√¢u? (xe c·ªô, c√¥ng nghi·ªáp, ƒë·ªët r∆°m)
- Time patterns: √î nhi·ªÖm cao v√†o gi·ªù n√†o? (gi·ªù cao ƒëi·ªÉm)
- Seasonal: M√πa n√†o t·ªá nh·∫•t? (m√πa ƒë√¥ng, ƒë·ªët r∆°m)

**Visualization:**
- Pie chart: Contribution of each pollutant to AQI
- Bar chart: PM2.5 by hour of day
- Heatmap: Day of week vs hour

**Policy impact:**
- ƒê·ªÅ xu·∫•t gi·∫£m xe c·ªô v√†o gi·ªù cao ƒëi·ªÉm
- C·∫•m ƒë·ªët r∆°m v√†o m√πa ƒë√¥ng

### 6. **AQI Chatbot (Integration with Zalo)**
**M√¥ t·∫£:** Chatbot tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠.

**Sample conversations:**
- User: "AQI h√¥m nay khu v·ª±c t√¥i th·∫ø n√†o?"
  Bot: "AQI 135 - Moderate. B·∫°n n√™n h·∫°n ch·∫ø ho·∫°t ƒë·ªông ngo√†i tr·ªùi k√©o d√†i."

- User: "Ng√†y mai c√≥ n√™n ƒëi ch·∫°y kh√¥ng?"
  Bot: "D·ª± b√°o AQI ng√†y mai: 88 (Good). Tuy·ªát v·ªùi ƒë·ªÉ ch·∫°y b·ªô! üèÉ"

- User: "Tr·∫°m n√†o g·∫ßn t√¥i?"
  Bot: "Tr·∫°m AP001 c√°ch b·∫°n 2km. AQI hi·ªán t·∫°i: 102."

**Features:**
- Natural language understanding (NLU)
- Location-based responses
- Personalized (d·ª±a v√†o user profile)

### 7. **Health Impact Calculator**
**M√¥ t·∫£:** T√≠nh to√°n t√°c ƒë·ªông s·ª©c kh·ªèe c·ªßa vi·ªác ti·∫øp x√∫c √¥ nhi·ªÖm.

**Input:**
- AQI h√¥m nay: 180
- Th·ªùi gian ·ªü ngo√†i tr·ªùi: 2 gi·ªù
- Profile: ng∆∞·ªùi l·ªõn kh·ªèe m·∫°nh

**Output:**
- Equivalent cigarettes: "2 gi·ªù ·ªü ngo√†i = h√∫t 3 ƒëi·∫øu thu·ªëc"
- Health risk: "TƒÉng 15% nguy c∆° vi√™m ƒë∆∞·ªùng h√¥ h·∫•p"
- Life expectancy impact: "Gi·∫£m 0.2 nƒÉm tu·ªïi th·ªç n·∫øu ti·∫øp x√∫c d√†i h·∫°n"

**Use case:**
- Awareness: Gi√∫p ng∆∞·ªùi d√πng hi·ªÉu r√µ t√°c h·∫°i
- Motivation: Khuy·∫øn kh√≠ch s·ª≠ d·ª•ng m√°y l·ªçc kh√¥ng kh√≠

### 8. **Automated Report Generation**
**M√¥ t·∫£:** T·ª± ƒë·ªông t·∫°o b√°o c√°o AQI ƒë·ªãnh k·ª≥ (h√†ng ng√†y/tu·∫ßn/th√°ng).

**n8n workflow:**
1. Schedule trigger (m·ªói s√°ng 8AM)
2. Query database cho d·ªØ li·ªáu h√¥m qua
3. Generate charts (Plotly)
4. Create PDF report (pdfkit)
5. Send email v·ªõi attachment
6. Post summary to Slack/Telegram
7. Archive report to Google Drive

**Report contents:**
- Yesterday's summary
- Week-over-week comparison
- Top 3 polluted stations
- Recommendations

### 9. **Air Purifier Control Integration**
**M√¥ t·∫£:** T·ª± ƒë·ªông b·∫≠t/t·∫Øt m√°y l·ªçc kh√¥ng kh√≠ d·ª±a tr√™n AQI.

**Integration v·ªõi smart home:**
- n8n monitor AQI real-time
- If AQI > 100 ‚Üí Send command to smart plug/IoT device
- Turn on air purifier automatically
- If AQI < 50 ‚Üí Turn off to save energy

**Platform:**
- Xiaomi Mi Home
- Tuya Smart
- Home Assistant
- IFTTT

### 10. **Crowdsourced AQI Data**
**M√¥ t·∫£:** Thu th·∫≠p d·ªØ li·ªáu AQI t·ª´ c·ªông ƒë·ªìng (low-cost sensors).

**Architecture:**
- Users v·ªõi PurpleAir/AirVisual sensor
- Submit data qua mobile app ho·∫∑c API
- n8n webhook nh·∫≠n data ‚Üí Validate ‚Üí Store
- Aggregate v·ªõi official station data
- Increase coverage (nhi·ªÅu ƒëi·ªÉm ƒëo h∆°n)

**Benefits:**
- Realtime coverage t·ªët h∆°n
- Community engagement
- Identify pollution hotspots

---

## üìà ƒê√ÅNH GI√Å V√Ä C·∫¢I TI·∫æN

### Metrics quan tr·ªçng

**Model Performance:**
- MAE (Mean Absolute Error) < 15 AQI points
- R¬≤ score > 0.85
- MAPE (Mean Absolute Percentage Error) < 10%

**System Performance:**
- API response time < 200ms
- Uptime > 99.5%
- Alert delivery < 30 seconds

**User Engagement:**
- Daily active users
- Alert open rate
- Chatbot conversation rate

### A/B Testing Ideas

1. **Alert Timing:** G·ª≠i c·∫£nh b√°o l√∫c n√†o hi·ªáu qu·∫£ nh·∫•t?
2. **Message Tone:** Formal vs friendly vs urgent
3. **Channels:** Zalo vs Email vs SMS - k√™nh n√†o t·ªët nh·∫•t?
4. **Recommendation Style:** Directive vs suggestive

---

## üöÄ K·∫æT LU·∫¨N

### Gi√° tr·ªã c·ªßa ƒë·ªì √°n

‚úÖ **Real-world impact:** B·∫£o v·ªá s·ª©c kh·ªèe c·ªông ƒë·ªìng  
‚úÖ **Technical skills:** ETL, ML, API, automation, dashboards  
‚úÖ **Scalable:** D·ªÖ m·ªü r·ªông th√™m tr·∫°m, pollutants, features  
‚úÖ **Innovation:** K·∫øt h·ª£p ML + automation + real-time alerting  

### Next Steps

1. ‚úÖ Ho√†n th√†nh ETL pipeline
2. ‚úÖ Train baseline model (Random Forest)
3. ‚úÖ Deploy FastAPI prediction service
4. ‚úÖ Build n8n daily alert workflow
5. ‚è≥ Create Streamlit dashboard
6. ‚è≥ Add chatbot integration
7. ‚è≥ Setup monitoring & logging
8. ‚è≥ Write documentation & demo video

---

**B·∫°n mu·ªën m√¨nh implement ph·∫ßn n√†o tr∆∞·ªõc?**
- ETL + EDA notebooks?
- Train model script?
- FastAPI AQI prediction endpoints?
- n8n daily alert workflow?
- Streamlit dashboard?
